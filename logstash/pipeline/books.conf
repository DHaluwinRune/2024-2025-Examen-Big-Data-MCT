input {
  s3 {
    bucket => "books-dataset-rune-dhaluwin"
    prefix => ""
    region => "${AWS_REGION}"
    access_key_id => "${AWS_ACCESS_KEY_ID}"
    secret_access_key => "${AWS_SECRET_ACCESS_KEY}"
    codec => "json_lines"
  }
}

filter {
  # Step 1: Split user location into separate fields (city, state, country)
  mutate {
    split => { "[user][location]" => ", " }
    add_field => {
      "[user][city]" => "%{[user][location][0]}"
      "[user][state]" => "%{[user][location][1]}"
      "[user][country]" => "%{[user][location][2]}"
    }
  }

  # Step 2: Clean up - remove the original location field
  mutate {
    remove_field => "[user][location]"
  }

  # Step 3: Convert numeric fields to proper types
  mutate {
    convert => { 
      "[user][user_id]" => "integer"
      "book_rating" => "integer"
    }
  }

  # Step 4: Handle age field - convert to integer or null
  if [user][age] == "" or [user][age] == "null" {
    mutate { replace => { "[user][age]" => nil } }
  } else {
    mutate { convert => { "[user][age]" => "integer" } }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "books_dataset"
    template => "/usr/share/logstash/data/books_template.json"
    template_name => "books"
    template_overwrite => true
  }
  stdout { codec => rubydebug }
}

